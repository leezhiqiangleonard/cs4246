{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install gym~=0.17.3\n",
    "# !pip install numpy==1.19.4\n",
    "# !pip install boolean.py@git+https://github.com/bastikr/boolean.py/@74063a8588875c058e6dbbb85b69ed052e1f2099#egg=boolpy_stubs\n",
    "# !pip install networkx==2.4\n",
    "# !pip install pyyaml~=5.4.1\n",
    "# !pip install setuptools~=49.2.1\n",
    "# !pip install matplotlib~=3.2.1\n",
    "# !pip install plotly~=4.11.0\n",
    "# !pip install tabulate~=0.8.7\n",
    "# !pip install ordered_set==4.0.2\n",
    "# !pip install progressbar2==3.51.4\n",
    "# !pip install decorator==4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import gym\n",
    "from gym.utils import seeding\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "import cyberbattle._env.cyberbattle_env as cyberbattle_env\n",
    "gym_env = gym.make('CyberBattleToyCtf-v0')\n",
    "\n",
    "import cyberbattle.simulation.model as model\n",
    "import cyberbattle.simulation.commandcontrol as commandcontrol\n",
    "import cyberbattle.samples.toyctf.toy_ctf as ctf\n",
    "import plotly.offline as plo\n",
    "plo.init_notebook_mode(connected=True)\n",
    "\n",
    "from cyberbattle.agents.baseline.agent_wrapper import EnvironmentBounds\n",
    "import cyberbattle.agents.baseline.agent_wrapper as w\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# gymid = 'CyberBattleTiny-v0'\n",
    "#############\n",
    "gymid = \"CyberBattleToyCtf-v0\"\n",
    "env_size = None\n",
    "# iteration_count = 1500\n",
    "iteration_count = 10\n",
    "training_episode_count = 20\n",
    "eval_episode_count = 10\n",
    "maximum_node_count = 12\n",
    "maximum_total_credentials = 10\n",
    "\n",
    "\n",
    "\n",
    "# Load the Gym environment\n",
    "if env_size:\n",
    "    gym_env = gym.make(gymid, size=env_size)\n",
    "else:\n",
    "    gym_env = gym.make(gymid)\n",
    "\n",
    "ep = w.EnvironmentBounds.of_identifiers(\n",
    "    maximum_node_count=maximum_node_count,\n",
    "    maximum_total_credentials=maximum_total_credentials,\n",
    "    identifiers=gym_env.identifiers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomPolicy(state, env, random):\n",
    "#     for debug\n",
    "# def randomPolicy(state,numiters, env, random):\n",
    "\n",
    "    '''\n",
    "    Policy followed in MCTS simulation for playout\n",
    "    '''\n",
    "    reward = 0.\n",
    "    count=0\n",
    "    while not state.isDone():\n",
    "# for debug\n",
    "#     for i in range(count):\n",
    "#         count=count+1\n",
    "#         print(\"count\")\n",
    "#         print(count)\n",
    "\n",
    "        action = gym_env.sample_valid_action()\n",
    "        \n",
    "# for debug\n",
    "#         state = state.simulateStep(env=env,ep=ep,count=count,numiters=numiters,action=action)\n",
    "        state = state.simulateStep(env=env,ep=ep,action=action)\n",
    "        reward += state.getReward()\n",
    "\n",
    "    \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyberBattleStateActionModel:\n",
    "    \"\"\" Define an abstraction of the state and action space\n",
    "        for a CyberBattle environment, to be used to train a Q-function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ep: EnvironmentBounds):\n",
    "        self.ep = ep\n",
    "\n",
    "        self.global_features = w.ConcatFeatures(ep, [\n",
    "            # w.Feature_discovered_node_count(ep),\n",
    "            # w.Feature_owned_node_count(ep),\n",
    "            w.Feature_discovered_notowned_node_count(ep, None)\n",
    "\n",
    "            # w.Feature_discovered_ports(ep),\n",
    "            # w.Feature_discovered_ports_counts(ep),\n",
    "            # w.Feature_discovered_ports_sliding(ep),\n",
    "            # w.Feature_discovered_credential_count(ep),\n",
    "            # w.Feature_discovered_nodeproperties_sliding(ep),\n",
    "        ])\n",
    "\n",
    "        self.node_specific_features = w.ConcatFeatures(ep, [\n",
    "            # w.Feature_actions_tried_at_node(ep),\n",
    "            w.Feature_success_actions_at_node(ep),\n",
    "            w.Feature_failed_actions_at_node(ep),\n",
    "            w.Feature_active_node_properties(ep),\n",
    "            w.Feature_active_node_age(ep)\n",
    "            # w.Feature_active_node_id(ep)\n",
    "        ])\n",
    "\n",
    "        self.state_space = w.ConcatFeatures(ep, self.global_features.feature_selection +\n",
    "                                            self.node_specific_features.feature_selection)\n",
    "\n",
    "        self.action_space = w.AbstractAction(ep)\n",
    "\n",
    "    def get_state_astensor(self, state: w.StateAugmentation):\n",
    "        state_vector = self.state_space.get(state, node=None)\n",
    "        state_vector_float = np.array(state_vector, dtype=np.float32)\n",
    "        state_tensor = torch.from_numpy(state_vector_float).unsqueeze(0)\n",
    "        return state_tensor\n",
    "\n",
    "    def implement_action(\n",
    "            self,\n",
    "            wrapped_env: w.AgentWrapper,\n",
    "            actor_features: np.ndarray,\n",
    "#             abstract_action: np.int32) -> Tuple[str, Optional[cyberbattle_env.Action], Optional[int]]:\n",
    "            abstract_action: np.int32):\n",
    "        \"\"\"Specialize an abstract model action into a CyberBattle gym action.\n",
    "\n",
    "            actor_features -- the desired features of the actor to use (source CyberBattle node)\n",
    "            abstract_action -- the desired type of attack (connect, local, remote).\n",
    "\n",
    "            Returns a gym environment implementing the desired attack at a node with the desired embedding.\n",
    "        \"\"\"\n",
    "\n",
    "        observation = wrapped_env.state.observation\n",
    "\n",
    "        # Pick source node at random (owned and with the desired feature encoding)\n",
    "        potential_source_nodes = [\n",
    "            from_node\n",
    "            for from_node in w.owned_nodes(observation)\n",
    "            if np.all(actor_features == self.node_specific_features.get(wrapped_env.state, from_node))\n",
    "        ]\n",
    "\n",
    "        if len(potential_source_nodes) > 0:\n",
    "            source_node = np.random.choice(potential_source_nodes)\n",
    "\n",
    "            gym_action = self.action_space.specialize_to_gymaction(\n",
    "                source_node, observation, np.int32(abstract_action))\n",
    "\n",
    "            if not gym_action:\n",
    "                return \"exploit[undefined]->explore\", None, None\n",
    "\n",
    "            elif wrapped_env.env.is_action_valid(gym_action, observation['action_mask']):\n",
    "                return \"exploit\", gym_action, source_node\n",
    "            else:\n",
    "                return \"exploit[invalid]->explore\", None, None\n",
    "        else:\n",
    "            return \"exploit[no_actor]->explore\", None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkState():\n",
    "# for debug\n",
    "#     def __init__(self, state, ep,count,numiters, done=False, reward = 0):\n",
    "    def __init__(self, state, ep, done=False, reward = 0):\n",
    "        '''\n",
    "        Data structure to represent state of the environment\n",
    "        self.env : Environment of gym_network_environment simulator\n",
    "        self.state : State of the gym_network_environment\n",
    "        self.is_done : Denotes whether the NetworkState is terminal\n",
    "        self.num_lanes : Number of nodes in gym_network_environment\n",
    "        self.width : Width of lanes in gym_network_environment\n",
    "        self.reward : Reward of the state\n",
    "        '''\n",
    "        self.state = deepcopy(state)\n",
    "        self.is_done = done\n",
    "        '''\n",
    "        TO ADD IS DONE CONDITION\n",
    "        '''     \n",
    "# for debug\n",
    "#         self.count=count+1\n",
    "#         if self.count>numiters:\n",
    "#             self.is_done=True\n",
    "        \n",
    "        self.reward = reward\n",
    "        \n",
    "        self.ep = ep\n",
    "\n",
    "        self.global_features = w.ConcatFeatures(ep, [\n",
    "            # w.Feature_discovered_node_count(ep),\n",
    "            # w.Feature_owned_node_count(ep),\n",
    "            w.Feature_discovered_notowned_node_count(ep, None)\n",
    "\n",
    "            # w.Feature_discovered_ports(ep),\n",
    "            # w.Feature_discovered_ports_counts(ep),\n",
    "            # w.Feature_discovered_ports_sliding(ep),\n",
    "            # w.Feature_discovered_credential_count(ep),\n",
    "            # w.Feature_discovered_nodeproperties_sliding(ep),\n",
    "        ])\n",
    "\n",
    "        self.node_specific_features = w.ConcatFeatures(ep, [\n",
    "            # w.Feature_actions_tried_at_node(ep),\n",
    "            w.Feature_success_actions_at_node(ep),\n",
    "            w.Feature_failed_actions_at_node(ep),\n",
    "            w.Feature_active_node_properties(ep),\n",
    "            w.Feature_active_node_age(ep)\n",
    "            # w.Feature_active_node_id(ep)\n",
    "        ])\n",
    "\n",
    "        self.state_space = w.ConcatFeatures(ep, self.global_features.feature_selection +\n",
    "                                            self.node_specific_features.feature_selection)\n",
    "\n",
    "        self.action_space = w.AbstractAction(ep)\n",
    "        \n",
    "    def get_state_astensor(self, state: w.StateAugmentation):\n",
    "        state_vector = self.state_space.get(state, node=None)\n",
    "        state_vector_float = np.array(state_vector, dtype=np.float32)\n",
    "        state_tensor = torch.from_numpy(state_vector_float).unsqueeze(0)\n",
    "        return state_tensor\n",
    "\n",
    "    def implement_action(\n",
    "            self,\n",
    "            wrapped_env: w.AgentWrapper,\n",
    "            actor_features: np.ndarray,\n",
    "#             abstract_action: np.int32) -> Tuple[str, Optional[cyberbattle_env.Action], Optional[int]]:\n",
    "            abstract_action: np.int32): \n",
    "        \"\"\"Specialize an abstract model action into a CyberBattle gym action.\n",
    "\n",
    "            actor_features -- the desired features of the actor to use (source CyberBattle node)\n",
    "            abstract_action -- the desired type of attack (connect, local, remote).\n",
    "\n",
    "            Returns a gym environment implementing the desired attack at a node with the desired embedding.\n",
    "        \"\"\"\n",
    "\n",
    "        observation = wrapped_env.state.observation\n",
    "\n",
    "        # Pick source node at random (owned and with the desired feature encoding)\n",
    "        potential_source_nodes = [\n",
    "            from_node\n",
    "            for from_node in w.owned_nodes(observation)\n",
    "            if np.all(actor_features == self.node_specific_features.get(wrapped_env.state, from_node))\n",
    "        ]\n",
    "\n",
    "        if len(potential_source_nodes) > 0:\n",
    "            source_node = np.random.choice(potential_source_nodes)\n",
    "\n",
    "            gym_action = self.action_space.specialize_to_gymaction(\n",
    "                source_node, observation, np.int32(abstract_action))\n",
    "\n",
    "            if not gym_action:\n",
    "                return \"exploit[undefined]->explore\", None, None\n",
    "\n",
    "            elif wrapped_env.env.is_action_valid(gym_action, observation['action_mask']):\n",
    "                return \"exploit\", gym_action, source_node\n",
    "            else:\n",
    "                return \"exploit[invalid]->explore\", None, None\n",
    "        else:\n",
    "            return \"exploit[no_actor]->explore\", None, None\n",
    "        \n",
    "#         for debug\n",
    "#     def simulateStep(self, env,ep,count,numiters, action):\n",
    "    def simulateStep(self, env,ep,action):\n",
    "        '''\n",
    "        Simulates action at self.state and returns the next state\n",
    "        '''\n",
    "        observation, reward, done, info = env.step(action=action)\n",
    "# for debug\n",
    "#         print(reward)\n",
    "#         print(done)\n",
    "#         print(info)\n",
    "#         print(count)\n",
    "                \n",
    "#         if count>numiters:\n",
    "#             self.is_done=True\n",
    "#       newState  = NetworkState(state=observation,ep=ep,count=count,numiters=numiters, done=self.is_done, reward=reward)\n",
    "        \n",
    "        newState  = NetworkState(state=observation,ep=ep,done=self.is_done, reward=reward)\n",
    "        return newState\n",
    "\n",
    "    def isDone(self):\n",
    "        '''\n",
    "        Returns whether the state is terminal\n",
    "        '''\n",
    "        return self.is_done\n",
    "\n",
    "    def getReward(self):\n",
    "        '''\n",
    "        Returns reward of the state\n",
    "        '''\n",
    "        return self.reward\n",
    "    \n",
    "    def actions(self):\n",
    "        _actions = [{a:e,}for a, e in self.state.action_space.spaces.items()]\n",
    "        return _actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, state, parent=None):\n",
    "        '''\n",
    "        Data structure for a node of the MCTS tree\n",
    "        self.state : GridWorld state represented by the node\n",
    "        self.parent : Parent of the node in the MCTS tree\n",
    "        self.numVisits : Number of times the node has been visited\n",
    "        self.totalReward : Sum of all rewards backpropagated to the node\n",
    "        self.isDone : Denotes whether the node represents a terminal state\n",
    "        self.allChildrenAdded : Denotes whether all actions from the node have been explored\n",
    "        self.children : Set of children of the node in the MCTS tree\n",
    "        '''\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.numVisits = 0\n",
    "        self.totalReward = state.reward #0\n",
    "        self.isDone = state.isDone()\n",
    "        self.allChildrenAdded = state.isDone()\n",
    "        self.children = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonteCarloTreeSearch:\n",
    "    def __init__(self, env, numiters, explorationParam, playoutPolicy=randomPolicy, random_seed=None):\n",
    "        '''\n",
    "        self.numiters : Number of MCTS iterations\n",
    "        self.explorationParam : exploration constant used in computing value of node\n",
    "        self.playoutPolicy : Policy followed by agent to simulate rollout from leaf node\n",
    "        self.root : root node of MCTS tree\n",
    "        '''\n",
    "        self.env = env\n",
    "        self.numiters = numiters\n",
    "        self.explorationParam = explorationParam\n",
    "        self.playoutPolicy = playoutPolicy\n",
    "        self.root = None\n",
    "        self.random, self.seed = seeding.np_random(random_seed)\n",
    "\n",
    "    def buildTreeAndReturnBestAction(self, initialState):\n",
    "        '''\n",
    "        Function to build MCTS tree and return best action at initialState\n",
    "        '''\n",
    "        self.root = Node(state=initialState, parent=None)\n",
    "        for i in range(self.numiters):\n",
    "            self.addNodeAndBackpropagate()\n",
    "        bestChild = self.chooseBestActionNode(self.root, 0)\n",
    "        for action, cur_node in self.root.children.items():\n",
    "            if cur_node is bestChild:\n",
    "               return action\n",
    "\n",
    "    def addNodeAndBackpropagate(self):\n",
    "        '''\n",
    "        Function to run a single MCTS iteration\n",
    "        '''\n",
    "        node = self.addNode()\n",
    "        reward = self.playoutPolicy(node.state, self.env, self.random)\n",
    "# for debug\n",
    "#         reward = self.playoutPolicy(node.state,self.numiters, self.env, self.random)\n",
    "        self.backpropagate(node, reward)\n",
    "        \n",
    "\n",
    "    def addNode(self):\n",
    "        '''\n",
    "        Function to add a node to the MCTS tree\n",
    "        '''\n",
    "        cur_node = self.root\n",
    "        while not cur_node.isDone:\n",
    "# for debug\n",
    "#         for i in range(numiters):\n",
    "            if cur_node.allChildrenAdded:\n",
    "                cur_node = self.chooseBestActionNode(cur_node, self.explorationParam)\n",
    "            else:\n",
    "#                 actions = self.env.actions\n",
    "#                 actions=list(gym_env.action_space)\n",
    "#                 for action in actions:\n",
    "                action= gym_env.action_space.sample()\n",
    "                action_str=str(action.keys())\n",
    "                print(action_str)\n",
    "                if action_str not in cur_node.children:\n",
    "#                     for debug\n",
    "#                     childnode = cur_node.state.simulateStep(env=self.env,ep=ep,count=0,numiters=numiters,action=action)\n",
    "                    childnode = cur_node.state.simulateStep(env=self.env,ep=ep,action=action)\n",
    "                    newNode = Node(state=childnode, parent=cur_node)\n",
    "#                     cur_node.children[action] = newNode\n",
    "                    cur_node.children[action_str] = newNode\n",
    "#                     if len(actions) == len(cur_node.children):\n",
    "                    if len(list(gym_env.action_space)) == len(cur_node.children):\n",
    "                        cur_node.allChildrenAdded = True\n",
    "                    return newNode\n",
    "        return cur_node\n",
    "\n",
    "    def backpropagate(self, node, reward):\n",
    "        '''\n",
    "        FILL ME : This function should implement the backpropation step of MCTS.\n",
    "                  Update the values of relevant variables in Node Class to complete this function\n",
    "        '''\n",
    "        while True:\n",
    "            # Add values to node\n",
    "            node.totalReward += reward\n",
    "            node.numVisits += 1\n",
    "\n",
    "            # Terminating Condition\n",
    "            if node.parent is None:\n",
    "                break\n",
    "\n",
    "            # Go to parent node\n",
    "            node = node.parent\n",
    "\n",
    "    def chooseBestActionNode(self, node, explorationValue):\n",
    "        random = self.random\n",
    "        bestValue = float(\"-inf\")\n",
    "        bestNodes = []\n",
    "        for child in node.children.values():\n",
    "            '''\n",
    "            FILL ME : Populate the list bestNodes with all children having maximum value\n",
    "\n",
    "                       Value of all nodes should be computed as mentioned in question 3(b).\n",
    "                       All the nodes that have the largest value should be included in the list bestNodes.\n",
    "                       We will then choose one of the nodes in this list at random as the best action node.\n",
    "            '''\n",
    "            # Get Child values\n",
    "            try:\n",
    "                child_value = (child.totalReward/child.numVisits) + \\\n",
    "                    explorationValue * math.sqrt((math.log(node.numVisits) / child.numVisits))\n",
    "            except ZeroDivisionError:  # Case if division by zero\n",
    "                child_value = 0\n",
    "\n",
    "            # Case if child value more than best value\n",
    "            if child_value > bestValue:\n",
    "                bestNodes = [child,]\n",
    "                bestValue = child_value\n",
    "            elif child_value == bestValue:  # Case if child value is best value\n",
    "                bestNodes.append(child)\n",
    "\n",
    "        return random.choice(bestNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from runner.abstracts import Agent\n",
    "except:\n",
    "    class Agent(object): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSAgent(Agent):\n",
    "    def initialize(self, env, numiters, random_seed):\n",
    "        self.env = env\n",
    "        self.numiters = numiters\n",
    "        self.random_seed = random_seed\n",
    "        self.explorationParam = 1.\n",
    "        self.mcts = MonteCarloTreeSearch(env=self.env, numiters=self.numiters,\n",
    "                explorationParam=self.explorationParam, random_seed=self.random_seed)\n",
    "\n",
    "    def step(self, state,numiters, *args, **kwargs) :\n",
    "        _state = NetworkState(state,numiters)\n",
    "        action = self.mcts.buildTreeAndReturnBestAction(initialState=_state)\n",
    "        return action\n",
    "\n",
    "def create_agent(test_case_env, *args, **kwargs):\n",
    "    return MCTSAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "      <th>properties</th>\n",
       "      <th>local_attacks</th>\n",
       "      <th>remote_attacks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>client</td>\n",
       "      <td>owned</td>\n",
       "      <td>[]</td>\n",
       "      <td>[SearchEdgeHistory]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id status properties        local_attacks remote_attacks\n",
       "0  client  owned         []  [SearchEdgeHistory]             []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "cumulative reward",
         "type": "scatter",
         "xaxis": "x",
         "y": [],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "gray"
         },
         "mode": "lines",
         "name": "KNOWS",
         "type": "scatter",
         "x": [
          0
         ],
         "xaxis": "x2",
         "y": [
          0
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "REMOTE_EXPLOIT",
         "type": "scatter",
         "x": [
          0
         ],
         "xaxis": "x2",
         "y": [
          0
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "LATERAL_MOVE",
         "type": "scatter",
         "x": [
          0
         ],
         "xaxis": "x2",
         "y": [
          0
         ],
         "yaxis": "y2"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "#D32F2E",
          "line": {
           "color": "rgb(255,0,0)",
           "width": 8
          },
          "size": 5,
          "symbol": "circle-dot"
         },
         "mode": "markers+text",
         "name": "owned",
         "text": [
          "client"
         ],
         "textposition": "bottom center",
         "type": "scatter",
         "x": [
          0
         ],
         "xaxis": "x2",
         "y": [
          0
         ],
         "yaxis": "y2"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "#0e9d00",
          "line": {
           "color": "rgb(0,255,0)",
           "width": 8
          },
          "size": 5,
          "symbol": "circle-dot"
         },
         "mode": "markers+text",
         "name": "discovered",
         "text": [],
         "textposition": "bottom center",
         "type": "scatter",
         "x": [],
         "xaxis": "x2",
         "y": [],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "autosize": false,
        "font": {
         "size": 10
        },
        "height": 400,
        "hovermode": "closest",
        "margin": {
         "b": 15,
         "l": 2,
         "r": 2,
         "t": 35
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "CyberBattle simulation"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ]
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"0b4a465d-a83c-45c1-9f93-b7e978677d5e\" class=\"plotly-graph-div\" style=\"height:400px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0b4a465d-a83c-45c1-9f93-b7e978677d5e\")) {                    Plotly.newPlot(                        \"0b4a465d-a83c-45c1-9f93-b7e978677d5e\",                        [{\"name\": \"cumulative reward\", \"type\": \"scatter\", \"xaxis\": \"x\", \"y\": [], \"yaxis\": \"y\"}, {\"line\": {\"color\": \"gray\"}, \"mode\": \"lines\", \"name\": \"KNOWS\", \"type\": \"scatter\", \"x\": [0], \"xaxis\": \"x2\", \"y\": [0], \"yaxis\": \"y2\"}, {\"line\": {\"color\": \"orange\"}, \"mode\": \"lines\", \"name\": \"REMOTE_EXPLOIT\", \"type\": \"scatter\", \"x\": [0], \"xaxis\": \"x2\", \"y\": [0], \"yaxis\": \"y2\"}, {\"line\": {\"color\": \"red\"}, \"mode\": \"lines\", \"name\": \"LATERAL_MOVE\", \"type\": \"scatter\", \"x\": [0], \"xaxis\": \"x2\", \"y\": [0], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"#D32F2E\", \"line\": {\"color\": \"rgb(255,0,0)\", \"width\": 8}, \"size\": 5, \"symbol\": \"circle-dot\"}, \"mode\": \"markers+text\", \"name\": \"owned\", \"text\": [\"client\"], \"textposition\": \"bottom center\", \"type\": \"scatter\", \"x\": [0.0], \"xaxis\": \"x2\", \"y\": [0.0], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"#0e9d00\", \"line\": {\"color\": \"rgb(0,255,0)\", \"width\": 8}, \"size\": 5, \"symbol\": \"circle-dot\"}, \"mode\": \"markers+text\", \"name\": \"discovered\", \"text\": [], \"textposition\": \"bottom center\", \"type\": \"scatter\", \"x\": [], \"xaxis\": \"x2\", \"y\": [], \"yaxis\": \"y2\"}],                        {\"autosize\": false, \"font\": {\"size\": 10}, \"height\": 400, \"hovermode\": \"closest\", \"margin\": {\"b\": 15, \"l\": 2, \"r\": 2, \"t\": 35}, \"showlegend\": true, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"CyberBattle simulation\"}, \"width\": 800, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0b4a465d-a83c-45c1-9f93-b7e978677d5e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Resetting the CyberBattle environment\n",
      "odict_keys(['connect'])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j5/by9y1wln5vdb758sk0f1swnm4ngs7r/T/ipykernel_3336/374776123.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#     net_state = NetworkState(state,ep,0,numiters,done=done)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildTreeAndReturnBestAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitialState\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;31m# for debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#     action = gym_env.sample_valid_action()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/j5/by9y1wln5vdb758sk0f1swnm4ngs7r/T/ipykernel_3336/897171876.py\u001b[0m in \u001b[0;36mbuildTreeAndReturnBestAction\u001b[0;34m(self, initialState)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitialState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumiters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddNodeAndBackpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mbestChild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchooseBestActionNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_node\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/j5/by9y1wln5vdb758sk0f1swnm4ngs7r/T/ipykernel_3336/897171876.py\u001b[0m in \u001b[0;36maddNodeAndBackpropagate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mFunction\u001b[0m \u001b[0mto\u001b[0m \u001b[0mrun\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mMCTS\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         '''\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayoutPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# for debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/j5/by9y1wln5vdb758sk0f1swnm4ngs7r/T/ipykernel_3336/897171876.py\u001b[0m in \u001b[0;36maddNode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m#                     for debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#                     childnode = cur_node.state.simulateStep(env=self.env,ep=ep,count=0,numiters=numiters,action=action)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                     \u001b[0mchildnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulateStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                     \u001b[0mnewNode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchildnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m#                     cur_node.children[action] = newNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/j5/by9y1wln5vdb758sk0f1swnm4ngs7r/T/ipykernel_3336/2600600223.py\u001b[0m in \u001b[0;36msimulateStep\u001b[0;34m(self, env, ep, action)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mSimulates\u001b[0m \u001b[0maction\u001b[0m \u001b[0mat\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         '''\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;31m# for debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m#         print(reward)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/OneDrive/Documents/IPP_SHOPEE_PHD/Modules/CS4246-CS5446/Project/Project Proposal/CyberBattleSim/cyberbattle/_env/cyberbattle_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__execute_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m             \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__observation_reward_from_action_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/OneDrive/Documents/IPP_SHOPEE_PHD/Modules/CS4246-CS5446/Project/Project Proposal/CyberBattleSim/cyberbattle/_env/cyberbattle_env.py\u001b[0m in \u001b[0;36m__execute_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0msource_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredential_cache_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"connect\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcredential_cache_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mcredential_cache_index\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__credential_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0msource_node_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal_node_id_from_external_node_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Sample test cases.\n",
    "\n",
    "RANDOM_SEED = 3\n",
    "# numiters = 500\n",
    "numiters = 10\n",
    "stochasticity = 1.\n",
    "\n",
    "gym_env = gym.make('CyberBattleToyCtf-v0')\n",
    "\n",
    "actions = gym_env.action_space.spaces\n",
    "gym_env.render()\n",
    "done = False\n",
    "mcts = MonteCarloTreeSearch(env=deepcopy(gym_env), numiters=numiters, explorationParam=1., random_seed=RANDOM_SEED)\n",
    "state = gym_env.reset()\n",
    "\n",
    "#for debug\n",
    "# count=0;\n",
    "# total_reward = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while not done:\n",
    "    \n",
    "# for debug\n",
    "# for t in range(iteration_count):\n",
    "\n",
    "    net_state = NetworkState(state,ep,done=done)\n",
    "#     net_state = NetworkState(state,ep,0,numiters,done=done)\n",
    "\n",
    "#     action = mcts.buildTreeAndReturnBestAction(initialState=net_state)\n",
    "# for debug\n",
    "    action = gym_env.sample_valid_action()\n",
    "    state, reward, done, info = gym_env.step(action)\n",
    "\n",
    "\n",
    "    total_reward += reward\n",
    "        \n",
    "    if reward>0:\n",
    "        print('####### rewarded action: {action}')\n",
    "        print(f'total_reward={total_reward} reward={reward}')\n",
    "        gym_env.render()\n",
    "    \n",
    "# for debug\n",
    "#     count=count+1\n",
    "#     if count==iteration_count:\n",
    "#         done = True\n",
    "#         break\n",
    "    \n",
    "    \n",
    "print (\"simulation done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
