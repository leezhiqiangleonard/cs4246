{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym~=0.17.3 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (0.17.3)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from gym~=0.17.3) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from gym~=0.17.3) (1.19.4)\n",
      "Requirement already satisfied: scipy in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from gym~=0.17.3) (1.7.1)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from gym~=0.17.3) (1.6.0)\n",
      "Requirement already satisfied: future in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from pyglet<=1.5.0,>=1.4.0->gym~=0.17.3) (0.18.2)\n",
      "Requirement already satisfied: numpy==1.19.4 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (1.19.4)\n",
      "Collecting boolean.py@ git+https://github.com/bastikr/boolean.py/@74063a8588875c058e6dbbb85b69ed052e1f2099#egg=boolpy_stubs\n",
      "  Using cached boolean.py-3.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: networkx==2.4 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (2.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from networkx==2.4) (4.3.0)\n",
      "Requirement already satisfied: pyyaml~=5.4.1 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (5.4.1)\n",
      "Requirement already satisfied: setuptools~=49.2.1 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (49.2.1)\n",
      "Requirement already satisfied: matplotlib~=3.2.1 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from matplotlib~=3.2.1) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from matplotlib~=3.2.1) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from matplotlib~=3.2.1) (1.19.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from matplotlib~=3.2.1) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from matplotlib~=3.2.1) (2.8.2)\n",
      "Requirement already satisfied: six in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from cycler>=0.10->matplotlib~=3.2.1) (1.16.0)\n",
      "Requirement already satisfied: plotly~=4.11.0 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages/plotly-4.11.0-py3.8.egg (4.11.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from plotly~=4.11.0) (1.3.3)\n",
      "Requirement already satisfied: six in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from plotly~=4.11.0) (1.16.0)\n",
      "Requirement already satisfied: tabulate~=0.8.7 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages/tabulate-0.8.9-py3.8.egg (0.8.9)\n",
      "Requirement already satisfied: ordered_set==4.0.2 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages/ordered_set-4.0.2-py3.8.egg (4.0.2)\n",
      "Requirement already satisfied: progressbar2==3.51.4 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages/progressbar2-3.51.4-py3.8.egg (3.51.4)\n",
      "Requirement already satisfied: python-utils>=2.3.0 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from progressbar2==3.51.4) (2.5.6)\n",
      "Requirement already satisfied: six in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (from progressbar2==3.51.4) (1.16.0)\n",
      "Requirement already satisfied: decorator==4.3 in /Users/leonard.lee/miniconda3/envs/jupyter3.8/lib/python3.8/site-packages (4.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym~=0.17.3\n",
    "!pip install numpy==1.19.4\n",
    "!pip install boolean.py@git+https://github.com/bastikr/boolean.py/@74063a8588875c058e6dbbb85b69ed052e1f2099#egg=boolpy_stubs\n",
    "!pip install networkx==2.4\n",
    "!pip install pyyaml~=5.4.1\n",
    "!pip install setuptools~=49.2.1\n",
    "!pip install matplotlib~=3.2.1\n",
    "!pip install plotly~=4.11.0\n",
    "!pip install tabulate~=0.8.7\n",
    "!pip install ordered_set==4.0.2\n",
    "!pip install progressbar2==3.51.4\n",
    "!pip install decorator==4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import gym\n",
    "from gym.utils import seeding\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "import cyberbattle._env.cyberbattle_env\n",
    "gym_env = gym.make('CyberBattleToyCtf-v0')\n",
    "\n",
    "import cyberbattle.simulation.model as model\n",
    "import cyberbattle.simulation.commandcontrol as commandcontrol\n",
    "import cyberbattle.samples.toyctf.toy_ctf as ctf\n",
    "import plotly.offline as plo\n",
    "plo.init_notebook_mode(connected=True)\n",
    "\n",
    "from cyberbattle.agents.baseline.agent_wrapper import EnvironmentBounds\n",
    "import cyberbattle.agents.baseline.agent_wrapper as w\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=\"%(levelname)s: %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomPolicy(state, env, random):\n",
    "    '''\n",
    "    Policy followed in MCTS simulation for playout\n",
    "    '''\n",
    "    reward = 0.\n",
    "    while not state.isDone():\n",
    "        action = gym_env.sample_valid_action()\n",
    "        state = state.simulateStep(env=env,action=action)\n",
    "        reward += state.getReward()\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyberBattleStateActionModel:\n",
    "    \"\"\" Define an abstraction of the state and action space\n",
    "        for a CyberBattle environment, to be used to train a Q-function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ep: EnvironmentBounds):\n",
    "        self.ep = ep\n",
    "\n",
    "        self.global_features = w.ConcatFeatures(ep, [\n",
    "            # w.Feature_discovered_node_count(ep),\n",
    "            # w.Feature_owned_node_count(ep),\n",
    "            w.Feature_discovered_notowned_node_count(ep, None)\n",
    "\n",
    "            # w.Feature_discovered_ports(ep),\n",
    "            # w.Feature_discovered_ports_counts(ep),\n",
    "            # w.Feature_discovered_ports_sliding(ep),\n",
    "            # w.Feature_discovered_credential_count(ep),\n",
    "            # w.Feature_discovered_nodeproperties_sliding(ep),\n",
    "        ])\n",
    "\n",
    "        self.node_specific_features = w.ConcatFeatures(ep, [\n",
    "            # w.Feature_actions_tried_at_node(ep),\n",
    "            w.Feature_success_actions_at_node(ep),\n",
    "            w.Feature_failed_actions_at_node(ep),\n",
    "            w.Feature_active_node_properties(ep),\n",
    "            w.Feature_active_node_age(ep)\n",
    "            # w.Feature_active_node_id(ep)\n",
    "        ])\n",
    "\n",
    "        self.state_space = w.ConcatFeatures(ep, self.global_features.feature_selection +\n",
    "                                            self.node_specific_features.feature_selection)\n",
    "\n",
    "        self.action_space = w.AbstractAction(ep)\n",
    "\n",
    "    def get_state_astensor(self, state: w.StateAugmentation):\n",
    "        state_vector = self.state_space.get(state, node=None)\n",
    "        state_vector_float = np.array(state_vector, dtype=np.float32)\n",
    "        state_tensor = torch.from_numpy(state_vector_float).unsqueeze(0)\n",
    "        return state_tensor\n",
    "\n",
    "    def implement_action(\n",
    "            self,\n",
    "            wrapped_env: w.AgentWrapper,\n",
    "            actor_features: ndarray,\n",
    "            abstract_action: np.int32) -> Tuple[str, Optional[cyberbattle_env.Action], Optional[int]]:\n",
    "        \"\"\"Specialize an abstract model action into a CyberBattle gym action.\n",
    "\n",
    "            actor_features -- the desired features of the actor to use (source CyberBattle node)\n",
    "            abstract_action -- the desired type of attack (connect, local, remote).\n",
    "\n",
    "            Returns a gym environment implementing the desired attack at a node with the desired embedding.\n",
    "        \"\"\"\n",
    "\n",
    "        observation = wrapped_env.state.observation\n",
    "\n",
    "        # Pick source node at random (owned and with the desired feature encoding)\n",
    "        potential_source_nodes = [\n",
    "            from_node\n",
    "            for from_node in w.owned_nodes(observation)\n",
    "            if np.all(actor_features == self.node_specific_features.get(wrapped_env.state, from_node))\n",
    "        ]\n",
    "\n",
    "        if len(potential_source_nodes) > 0:\n",
    "            source_node = np.random.choice(potential_source_nodes)\n",
    "\n",
    "            gym_action = self.action_space.specialize_to_gymaction(\n",
    "                source_node, observation, np.int32(abstract_action))\n",
    "\n",
    "            if not gym_action:\n",
    "                return \"exploit[undefined]->explore\", None, None\n",
    "\n",
    "            elif wrapped_env.env.is_action_valid(gym_action, observation['action_mask']):\n",
    "                return \"exploit\", gym_action, source_node\n",
    "            else:\n",
    "                return \"exploit[invalid]->explore\", None, None\n",
    "        else:\n",
    "            return \"exploit[no_actor]->explore\", None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkState():\n",
    "    def __init__(self, state, ep, done=False, reward = 0):\n",
    "        '''\n",
    "        Data structure to represent state of the environment\n",
    "        self.env : Environment of gym_network_environment simulator\n",
    "        self.state : State of the gym_network_environment\n",
    "        self.is_done : Denotes whether the NetworkState is terminal\n",
    "        self.num_lanes : Number of nodes in gym_network_environment\n",
    "        self.width : Width of lanes in gym_network_environment\n",
    "        self.reward : Reward of the state\n",
    "        '''\n",
    "        self.state = deepcopy(state)\n",
    "        self.is_done = done\n",
    "        self.reward = reward\n",
    "        \n",
    "        self.ep = ep\n",
    "\n",
    "        self.global_features = w.ConcatFeatures(ep, [\n",
    "            # w.Feature_discovered_node_count(ep),\n",
    "            # w.Feature_owned_node_count(ep),\n",
    "            w.Feature_discovered_notowned_node_count(ep, None)\n",
    "\n",
    "            # w.Feature_discovered_ports(ep),\n",
    "            # w.Feature_discovered_ports_counts(ep),\n",
    "            # w.Feature_discovered_ports_sliding(ep),\n",
    "            # w.Feature_discovered_credential_count(ep),\n",
    "            # w.Feature_discovered_nodeproperties_sliding(ep),\n",
    "        ])\n",
    "\n",
    "        self.node_specific_features = w.ConcatFeatures(ep, [\n",
    "            # w.Feature_actions_tried_at_node(ep),\n",
    "            w.Feature_success_actions_at_node(ep),\n",
    "            w.Feature_failed_actions_at_node(ep),\n",
    "            w.Feature_active_node_properties(ep),\n",
    "            w.Feature_active_node_age(ep)\n",
    "            # w.Feature_active_node_id(ep)\n",
    "        ])\n",
    "\n",
    "        self.state_space = w.ConcatFeatures(ep, self.global_features.feature_selection +\n",
    "                                            self.node_specific_features.feature_selection)\n",
    "\n",
    "        self.action_space = w.AbstractAction(ep)\n",
    "        \n",
    "    def get_state_astensor(self, state: w.StateAugmentation):\n",
    "        state_vector = self.state_space.get(state, node=None)\n",
    "        state_vector_float = np.array(state_vector, dtype=np.float32)\n",
    "        state_tensor = torch.from_numpy(state_vector_float).unsqueeze(0)\n",
    "        return state_tensor\n",
    "\n",
    "    def implement_action(\n",
    "            self,\n",
    "            wrapped_env: w.AgentWrapper,\n",
    "            actor_features: ndarray,\n",
    "            abstract_action: np.int32) -> Tuple[str, Optional[cyberbattle_env.Action], Optional[int]]:\n",
    "        \"\"\"Specialize an abstract model action into a CyberBattle gym action.\n",
    "\n",
    "            actor_features -- the desired features of the actor to use (source CyberBattle node)\n",
    "            abstract_action -- the desired type of attack (connect, local, remote).\n",
    "\n",
    "            Returns a gym environment implementing the desired attack at a node with the desired embedding.\n",
    "        \"\"\"\n",
    "\n",
    "        observation = wrapped_env.state.observation\n",
    "\n",
    "        # Pick source node at random (owned and with the desired feature encoding)\n",
    "        potential_source_nodes = [\n",
    "            from_node\n",
    "            for from_node in w.owned_nodes(observation)\n",
    "            if np.all(actor_features == self.node_specific_features.get(wrapped_env.state, from_node))\n",
    "        ]\n",
    "\n",
    "        if len(potential_source_nodes) > 0:\n",
    "            source_node = np.random.choice(potential_source_nodes)\n",
    "\n",
    "            gym_action = self.action_space.specialize_to_gymaction(\n",
    "                source_node, observation, np.int32(abstract_action))\n",
    "\n",
    "            if not gym_action:\n",
    "                return \"exploit[undefined]->explore\", None, None\n",
    "\n",
    "            elif wrapped_env.env.is_action_valid(gym_action, observation['action_mask']):\n",
    "                return \"exploit\", gym_action, source_node\n",
    "            else:\n",
    "                return \"exploit[invalid]->explore\", None, None\n",
    "        else:\n",
    "            return \"exploit[no_actor]->explore\", None, None\n",
    "        \n",
    "        \n",
    "    def simulateStep(self, env, action):\n",
    "        '''\n",
    "        Simulates action at self.state and returns the next state\n",
    "        '''\n",
    "        observation, reward, done, info = env.step(action=action)\n",
    "        newState  = NetworkState(state=observation, done=done, reward=reward)\n",
    "        return newState\n",
    "\n",
    "    def isDone(self):\n",
    "        '''\n",
    "        Returns whether the state is terminal\n",
    "        '''\n",
    "        return self.is_done\n",
    "\n",
    "    def getReward(self):\n",
    "        '''\n",
    "        Returns reward of the state\n",
    "        '''\n",
    "        return self.reward\n",
    "    \n",
    "    def actions(self):\n",
    "        _actions = [{a:e,}for a, e in self.state.action_space.spaces.items()]\n",
    "        return _actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, state, parent=None):\n",
    "        '''\n",
    "        Data structure for a node of the MCTS tree\n",
    "        self.state : GridWorld state represented by the node\n",
    "        self.parent : Parent of the node in the MCTS tree\n",
    "        self.numVisits : Number of times the node has been visited\n",
    "        self.totalReward : Sum of all rewards backpropagated to the node\n",
    "        self.isDone : Denotes whether the node represents a terminal state\n",
    "        self.allChildrenAdded : Denotes whether all actions from the node have been explored\n",
    "        self.children : Set of children of the node in the MCTS tree\n",
    "        '''\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.numVisits = 0\n",
    "        self.totalReward = state.reward #0\n",
    "        self.isDone = state.isDone()\n",
    "        self.allChildrenAdded = state.isDone()\n",
    "        self.children = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonteCarloTreeSearch:\n",
    "    def __init__(self, env, numiters, explorationParam, playoutPolicy=randomPolicy, random_seed=None):\n",
    "        '''\n",
    "        self.numiters : Number of MCTS iterations\n",
    "        self.explorationParam : exploration constant used in computing value of node\n",
    "        self.playoutPolicy : Policy followed by agent to simulate rollout from leaf node\n",
    "        self.root : root node of MCTS tree\n",
    "        '''\n",
    "        self.env = env\n",
    "        self.numiters = numiters\n",
    "        self.explorationParam = explorationParam\n",
    "        self.playoutPolicy = playoutPolicy\n",
    "        self.root = None\n",
    "        self.random, self.seed = seeding.np_random(random_seed)\n",
    "\n",
    "    def buildTreeAndReturnBestAction(self, initialState):\n",
    "        '''\n",
    "        Function to build MCTS tree and return best action at initialState\n",
    "        '''\n",
    "        self.root = Node(state=initialState, parent=None)\n",
    "        for i in range(self.numiters):\n",
    "            self.addNodeAndBackpropagate()\n",
    "        bestChild = self.chooseBestActionNode(self.root, 0)\n",
    "        for action, cur_node in self.root.children.items():\n",
    "            if cur_node is bestChild:\n",
    "               return action\n",
    "\n",
    "    def addNodeAndBackpropagate(self):\n",
    "        '''\n",
    "        Function to run a single MCTS iteration\n",
    "        '''\n",
    "        node = self.addNode()\n",
    "        reward = self.playoutPolicy(node.state, self.env, self.random)\n",
    "        self.backpropagate(node, reward)\n",
    "\n",
    "    def addNode(self):\n",
    "        '''\n",
    "        Function to add a node to the MCTS tree\n",
    "        '''\n",
    "        cur_node = self.root\n",
    "        while not cur_node.isDone:\n",
    "            if cur_node.allChildrenAdded:\n",
    "                cur_node = self.chooseBestActionNode(cur_node, self.explorationParam)\n",
    "            else:\n",
    "                actions = self.env.actions\n",
    "                for action in actions:\n",
    "                    if action not in cur_node.children:\n",
    "                        childnode = cur_node.state.simulateStep(env=self.env, action=action)\n",
    "                        newNode = Node(state=childnode, parent=cur_node)\n",
    "                        cur_node.children[action] = newNode\n",
    "                        if len(actions) == len(cur_node.children):\n",
    "                            cur_node.allChildrenAdded = True\n",
    "                        return newNode\n",
    "        return cur_node\n",
    "\n",
    "    def backpropagate(self, node, reward):\n",
    "        '''\n",
    "        FILL ME : This function should implement the backpropation step of MCTS.\n",
    "                  Update the values of relevant variables in Node Class to complete this function\n",
    "        '''\n",
    "        while True:\n",
    "            # Add values to node\n",
    "            node.totalReward += reward\n",
    "            node.numVisits += 1\n",
    "\n",
    "            # Terminating Condition\n",
    "            if node.parent is None:\n",
    "                break\n",
    "\n",
    "            # Go to parent node\n",
    "            node = node.parent\n",
    "\n",
    "    def chooseBestActionNode(self, node, explorationValue):\n",
    "        random = self.random\n",
    "        bestValue = float(\"-inf\")\n",
    "        bestNodes = []\n",
    "        for child in node.children.values():\n",
    "            '''\n",
    "            FILL ME : Populate the list bestNodes with all children having maximum value\n",
    "\n",
    "                       Value of all nodes should be computed as mentioned in question 3(b).\n",
    "                       All the nodes that have the largest value should be included in the list bestNodes.\n",
    "                       We will then choose one of the nodes in this list at random as the best action node.\n",
    "            '''\n",
    "            # Get Child values\n",
    "            try:\n",
    "                child_value = (child.totalReward/child.numVisits) + \\\n",
    "                    explorationValue * math.sqrt((math.log(node.numVisits) / child.numVisits))\n",
    "            except ZeroDivisionError:  # Case if division by zero\n",
    "                child_value = 0\n",
    "\n",
    "            # Case if child value more than best value\n",
    "            if child_value > bestValue:\n",
    "                bestNodes = [child,]\n",
    "                bestValue = child_value\n",
    "            elif child_value == bestValue:  # Case if child value is best value\n",
    "                bestNodes.append(child)\n",
    "\n",
    "        return random.choice(bestNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from runner.abstracts import Agent\n",
    "except:\n",
    "    class Agent(object): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSAgent(Agent):\n",
    "    def initialize(self, env, numiters, random_seed):\n",
    "        self.env = env\n",
    "        self.numiters = numiters\n",
    "        self.random_seed = random_seed\n",
    "        self.explorationParam = 1.\n",
    "        self.mcts = MonteCarloTreeSearch(env=self.env, numiters=self.numiters,\n",
    "                explorationParam=self.explorationParam, random_seed=self.random_seed)\n",
    "\n",
    "    def step(self, state, *args, **kwargs) :\n",
    "        _state = NetworkState(state)\n",
    "        action = self.mcts.buildTreeAndReturnBestAction(initialState=_state)\n",
    "        return action\n",
    "\n",
    "def create_agent(test_case_env, *args, **kwargs):\n",
    "    return MCTSAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "      <th>properties</th>\n",
       "      <th>local_attacks</th>\n",
       "      <th>remote_attacks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>client</td>\n",
       "      <td>owned</td>\n",
       "      <td>[]</td>\n",
       "      <td>[SearchEdgeHistory]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id status properties        local_attacks remote_attacks\n",
       "0  client  owned         []  [SearchEdgeHistory]             []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "cumulative reward",
         "type": "scatter",
         "xaxis": "x",
         "y": [],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "gray"
         },
         "mode": "lines",
         "name": "KNOWS",
         "type": "scatter",
         "x": [
          0
         ],
         "xaxis": "x2",
         "y": [
          0
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "REMOTE_EXPLOIT",
         "type": "scatter",
         "x": [
          0
         ],
         "xaxis": "x2",
         "y": [
          0
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "LATERAL_MOVE",
         "type": "scatter",
         "x": [
          0
         ],
         "xaxis": "x2",
         "y": [
          0
         ],
         "yaxis": "y2"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "#D32F2E",
          "line": {
           "color": "rgb(255,0,0)",
           "width": 8
          },
          "size": 5,
          "symbol": "circle-dot"
         },
         "mode": "markers+text",
         "name": "owned",
         "text": [
          "client"
         ],
         "textposition": "bottom center",
         "type": "scatter",
         "x": [
          0
         ],
         "xaxis": "x2",
         "y": [
          0
         ],
         "yaxis": "y2"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "#0e9d00",
          "line": {
           "color": "rgb(0,255,0)",
           "width": 8
          },
          "size": 5,
          "symbol": "circle-dot"
         },
         "mode": "markers+text",
         "name": "discovered",
         "text": [],
         "textposition": "bottom center",
         "type": "scatter",
         "x": [],
         "xaxis": "x2",
         "y": [],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "autosize": false,
        "font": {
         "size": 10
        },
        "height": 400,
        "hovermode": "closest",
        "margin": {
         "b": 15,
         "l": 2,
         "r": 2,
         "t": 35
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "CyberBattle simulation"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ]
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"7fd34701-8f64-4a15-be13-fe21c9a975cd\" class=\"plotly-graph-div\" style=\"height:400px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7fd34701-8f64-4a15-be13-fe21c9a975cd\")) {                    Plotly.newPlot(                        \"7fd34701-8f64-4a15-be13-fe21c9a975cd\",                        [{\"name\": \"cumulative reward\", \"type\": \"scatter\", \"xaxis\": \"x\", \"y\": [], \"yaxis\": \"y\"}, {\"line\": {\"color\": \"gray\"}, \"mode\": \"lines\", \"name\": \"KNOWS\", \"type\": \"scatter\", \"x\": [0], \"xaxis\": \"x2\", \"y\": [0], \"yaxis\": \"y2\"}, {\"line\": {\"color\": \"orange\"}, \"mode\": \"lines\", \"name\": \"REMOTE_EXPLOIT\", \"type\": \"scatter\", \"x\": [0], \"xaxis\": \"x2\", \"y\": [0], \"yaxis\": \"y2\"}, {\"line\": {\"color\": \"red\"}, \"mode\": \"lines\", \"name\": \"LATERAL_MOVE\", \"type\": \"scatter\", \"x\": [0], \"xaxis\": \"x2\", \"y\": [0], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"#D32F2E\", \"line\": {\"color\": \"rgb(255,0,0)\", \"width\": 8}, \"size\": 5, \"symbol\": \"circle-dot\"}, \"mode\": \"markers+text\", \"name\": \"owned\", \"text\": [\"client\"], \"textposition\": \"bottom center\", \"type\": \"scatter\", \"x\": [0.0], \"xaxis\": \"x2\", \"y\": [0.0], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"#0e9d00\", \"line\": {\"color\": \"rgb(0,255,0)\", \"width\": 8}, \"size\": 5, \"symbol\": \"circle-dot\"}, \"mode\": \"markers+text\", \"name\": \"discovered\", \"text\": [], \"textposition\": \"bottom center\", \"type\": \"scatter\", \"x\": [], \"xaxis\": \"x2\", \"y\": [], \"yaxis\": \"y2\"}],                        {\"autosize\": false, \"font\": {\"size\": 10}, \"height\": 400, \"hovermode\": \"closest\", \"margin\": {\"b\": 15, \"l\": 2, \"r\": 2, \"t\": 35}, \"showlegend\": true, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"CyberBattle simulation\"}, \"width\": 800, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('7fd34701-8f64-4a15-be13-fe21c9a975cd');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Resetting the CyberBattle environment\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CyberBattleToyCtf' object has no attribute 'actions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j5/by9y1wln5vdb758sk0f1swnm4ngs7r/T/ipykernel_28163/1564901730.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnet_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetworkState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildTreeAndReturnBestAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitialState\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mgym_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/j5/by9y1wln5vdb758sk0f1swnm4ngs7r/T/ipykernel_28163/873547566.py\u001b[0m in \u001b[0;36mbuildTreeAndReturnBestAction\u001b[0;34m(self, initialState)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitialState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumiters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddNodeAndBackpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mbestChild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchooseBestActionNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_node\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/j5/by9y1wln5vdb758sk0f1swnm4ngs7r/T/ipykernel_28163/873547566.py\u001b[0m in \u001b[0;36maddNodeAndBackpropagate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mFunction\u001b[0m \u001b[0mto\u001b[0m \u001b[0mrun\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mMCTS\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         '''\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayoutPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/j5/by9y1wln5vdb758sk0f1swnm4ngs7r/T/ipykernel_28163/873547566.py\u001b[0m in \u001b[0;36maddNode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mcur_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchooseBestActionNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplorationParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcur_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CyberBattleToyCtf' object has no attribute 'actions'"
     ]
    }
   ],
   "source": [
    "### Sample test cases.\n",
    "\n",
    "RANDOM_SEED = 10\n",
    "numiters = 500\n",
    "stochasticity = 1.\n",
    "\n",
    "gym_env = gym.make('CyberBattleToyCtf-v0')\n",
    "\n",
    "actions = gym_env.action_space.spaces\n",
    "gym_env.render()\n",
    "done = False\n",
    "mcts = MonteCarloTreeSearch(env=deepcopy(gym_env), numiters=numiters, explorationParam=1., random_seed=RANDOM_SEED)\n",
    "state = gym_env.reset()\n",
    "while not done:\n",
    "    net_state = NetworkState(state, done=done)\n",
    "    action = mcts.buildTreeAndReturnBestAction(initialState=net_state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    gym_env.render()\n",
    "    if done == True:\n",
    "        break\n",
    "print (\"simulation done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('testcase', type=int, help='test case number')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    ### Sample test cases.\n",
    "    test_config = [{'lanes' : [LaneSpec(1, [-1, -1])] *3,'width' :5, 'seed' : 10, 'iters': 300},\n",
    "                   {'lanes' : [LaneSpec(2, [-2, -1])] *3,'width' :7, 'seed' : 15, 'iters': 100},\n",
    "                   {'lanes' : [LaneSpec(2, [-2, -1])] *4,'width' :8, 'seed' : 125, 'iters': 500},\n",
    "                   {'lanes' : [LaneSpec(2, [-3, -2])] *4,'width' :10, 'seed' : 44, 'iters': 300},\n",
    "                   {'lanes' : [LaneSpec(2, [-3, -1])] *4,'width' :10, 'seed' : 125, 'iters': 400},\n",
    "                   {'lanes' : [LaneSpec(2, [-3, -1])] *4,'width' :10, 'seed' : 25, 'iters': 300}]\n",
    "\n",
    "    test_case_number = args.testcase\n",
    "    LANES = test_config[test_case_number]['lanes']\n",
    "    WIDTH = test_config[test_case_number]['width']\n",
    "    RANDOM_SEED = test_config[test_case_number]['seed']\n",
    "    numiters = test_config[test_case_number]['iters']\n",
    "    stochasticity = 1.\n",
    "    env = gym.make('GridDriving-v0', lanes=LANES, width=WIDTH,\n",
    "                   agent_speed_range=(-3,-1), finish_position=Point(0,0), #agent_ pos_init=Point(4,2),\n",
    "                   stochasticity=stochasticity, tensor_state=False, flicker_rate=0., mask=None, random_seed=RANDOM_SEED)\n",
    "\n",
    "    actions = env.actions\n",
    "    env.render()\n",
    "    done = False\n",
    "    mcts = MonteCarloTreeSearch(env=deepcopy(env), numiters=numiters, explorationParam=1.,random_seed=RANDOM_SEED)\n",
    "    state = env.reset()\n",
    "    while not done:\n",
    "        gw_state = GridWorldState(state)\n",
    "        action = mcts.buildTreeAndReturnBestAction(initialState=gw_state)\n",
    "        print (action)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        if done == True:\n",
    "            break\n",
    "    print (\"simulation done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
